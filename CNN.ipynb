{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Flatten, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_df = pd.read_csv(\"./df_file.csv\")\n",
    "\n",
    "X = text_df['Text'].tolist()\n",
    "y = text_df['Label'].tolist()\n",
    "\n",
    "sns.countplot(x=y)\n",
    "plt.title('Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text (fit on training data only)\n",
    "max_words = 1000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to have consistent length\n",
    "max_len = 100  # You can adjust this based on your dataset\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to NumPy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_embeddings = min(500, 5/2)\n",
    "num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 1000)         1000000   \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 96, 128)           640128    \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,650,629\n",
      "Trainable params: 1,650,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "embedding_dim = 1000 #50\n",
    "vocab_size = min(max_words, len(tokenizer.word_index) + 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 7s 234ms/step - loss: 1.5284 - accuracy: 0.3577 - val_loss: 1.3564 - val_accuracy: 0.4438\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 6s 241ms/step - loss: 1.1241 - accuracy: 0.5743 - val_loss: 0.9344 - val_accuracy: 0.7079\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 7s 257ms/step - loss: 0.5909 - accuracy: 0.8277 - val_loss: 0.5744 - val_accuracy: 0.8034\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 7s 263ms/step - loss: 0.1720 - accuracy: 0.9688 - val_loss: 0.4339 - val_accuracy: 0.8427\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 8s 312ms/step - loss: 0.0414 - accuracy: 0.9981 - val_loss: 0.3525 - val_accuracy: 0.8933\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 8s 309ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9157\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 7s 270ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9045\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 7s 260ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9157\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 7s 256ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9101\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 7s 254ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9157\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 6s 247ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9101\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 6s 250ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9101\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 6s 249ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9101\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 7s 269ms/step - loss: 9.8728e-04 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9101\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 6s 245ms/step - loss: 8.4394e-04 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9101\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 7s 260ms/step - loss: 7.3569e-04 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9101\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 7s 248ms/step - loss: 6.4449e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9101\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 5.7077e-04 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9101\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 6s 231ms/step - loss: 5.0951e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9101\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 4.5724e-04 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9101\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 4.1331e-04 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.9101\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 7s 256ms/step - loss: 3.7480e-04 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9101\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 8s 304ms/step - loss: 3.4166e-04 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9101\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 3.1296e-04 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9101\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 2.9475e-04 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9101\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 2.6535e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9157\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 2.4232e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9045\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 2.2620e-04 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.8989\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 2.0748e-04 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9045\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 1.9303e-04 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9101\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 1.8007e-04 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9101\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 6s 227ms/step - loss: 1.6842e-04 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9045\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 1.5808e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.8989\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 6s 230ms/step - loss: 1.4879e-04 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9101\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 1.3973e-04 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9045\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 6s 226ms/step - loss: 1.3175e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9101\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 6s 248ms/step - loss: 1.2429e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9101\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 1.1784e-04 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9045\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 8s 299ms/step - loss: 1.1131e-04 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9101\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 1.0565e-04 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9045\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 9.9924e-05 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9101\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 9.4847e-05 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9101\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 8s 299ms/step - loss: 9.0301e-05 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9101\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 8s 305ms/step - loss: 8.5885e-05 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9045\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 8.1920e-05 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9045\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 7.8507e-05 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9045\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 8s 302ms/step - loss: 7.5500e-05 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9045\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 7.1612e-05 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9045\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 8s 306ms/step - loss: 6.8279e-05 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9101\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 6.5346e-05 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9101\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 8s 303ms/step - loss: 6.2371e-05 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9101\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 5.9671e-05 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.8989\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 8s 299ms/step - loss: 5.7198e-05 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9045\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 6s 233ms/step - loss: 5.4899e-05 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9045\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 6s 232ms/step - loss: 5.2937e-05 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9045\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 6s 228ms/step - loss: 5.0796e-05 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9045\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 6s 231ms/step - loss: 4.8774e-05 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9045\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 7s 280ms/step - loss: 4.6998e-05 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9045\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 8s 307ms/step - loss: 4.5260e-05 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9045\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 4.3584e-05 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9045\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 8s 302ms/step - loss: 4.2029e-05 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9045\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 4.0529e-05 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9045\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 3.9190e-05 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9045\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 3.7775e-05 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9045\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 3.6561e-05 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9045\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 8s 297ms/step - loss: 3.5251e-05 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9045\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 3.4026e-05 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9045\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 3.2932e-05 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9045\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 3.1902e-05 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9045\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 3.0890e-05 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9045\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 8s 299ms/step - loss: 2.9928e-05 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9045\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 2.9011e-05 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9045\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 8s 302ms/step - loss: 2.8141e-05 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9045\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 2.7282e-05 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9045\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 2.6451e-05 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9045\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 2.5677e-05 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9045\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 2.4927e-05 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9045\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 2.4175e-05 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9045\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 2.3478e-05 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9045\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 2.2778e-05 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9045\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 2.2119e-05 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9045\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 2.1506e-05 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9045\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 2.0925e-05 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9045\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 2.0351e-05 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9045\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 8s 295ms/step - loss: 1.9795e-05 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9045\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 8s 294ms/step - loss: 1.9268e-05 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9045\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 8s 301ms/step - loss: 1.8757e-05 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9045\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 8s 308ms/step - loss: 1.8266e-05 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9045\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 8s 298ms/step - loss: 1.7783e-05 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9045\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 8s 292ms/step - loss: 1.7326e-05 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9045\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 8s 308ms/step - loss: 1.6885e-05 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9045\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 1.6453e-05 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9045\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 8s 303ms/step - loss: 1.6039e-05 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9045\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 8s 300ms/step - loss: 1.5634e-05 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9045\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 8s 303ms/step - loss: 1.5242e-05 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9045\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 1.4845e-05 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9045\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 8s 296ms/step - loss: 1.4476e-05 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9045\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 7s 262ms/step - loss: 1.4117e-05 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9045\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 6s 225ms/step - loss: 1.3777e-05 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9045\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 6s 223ms/step - loss: 1.3428e-05 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9045\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15625859480>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "callback = EarlyStopping(monitor='loss', patience=5)\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 31ms/step - loss: 0.3731 - accuracy: 0.9079\n",
      "Test accuracy: 0.9078651666641235\n",
      "14/14 [==============================] - 1s 31ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        84\n",
      "           1       0.93      0.99      0.96       102\n",
      "           2       0.87      0.89      0.88        80\n",
      "           3       0.97      0.84      0.90        77\n",
      "           4       0.89      0.90      0.90       102\n",
      "\n",
      "    accuracy                           0.91       445\n",
      "   macro avg       0.91      0.90      0.91       445\n",
      "weighted avg       0.91      0.91      0.91       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, predicted_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
